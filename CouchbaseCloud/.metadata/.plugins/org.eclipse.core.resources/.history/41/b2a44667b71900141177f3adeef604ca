from couchbase.stats_tools import StatsCommon
from xdcrbasetests import XDCRReplicationBaseTest
from couchbase.documentgenerator import BlobGenerator

class XdcrMiscTests(XDCRReplicationBaseTest):
    def setUp(self):
        super(XdcrMiscTests, self).setUp()

    def tearDown(self):
        super(XdcrMiscTests, self).tearDown()

    def setup_extended(self):
        pass

    def __setup_replication_clusters(self, src_master, dest_master, src_cluster_name, dest_cluster_name):
        self._link_clusters(src_cluster_name, src_master, dest_cluster_name, dest_master)
        self._link_clusters(dest_cluster_name, dest_master, src_cluster_name, src_master)

    def test_verify_mb8825(self):
        # Setting up replication clusters.
        src_cluster_name, dest_cluster_name = "remote-dest-src", "remote-src-dest"
        self.__setup_replication_clusters(self.src_master, self.dest_master, src_cluster_name, dest_cluster_name)

        # Step-3 Load 10k items ( sets=80, deletes=20) on source cluster.
        self._load_all_buckets(self.src_master, self.gen_create, "create", 0)

        # Step-4 XDCR Source -> Remote
        self._replicate_clusters(self.src_master, dest_cluster_name)
        self.merge_buckets(self.src_master, self.dest_master, bidirection=False)

        # Step-5 Wait for replication to finish 50% at destination node
        expected_items = (self.gen_create.end) * 0.5
        dest_master_buckets = self._get_cluster_buckets(self.dest_master)

        tasks = []
        for bucket in dest_master_buckets:
            tasks.append(self.cluster.async_wait_for_stats([self.dest_master], bucket, '', 'curr_items', '>=', expected_items))
        for task in tasks:
            task.result(self.wait_timeout * 5)

        # Perform 20% delete on Source cluster.
        tasks = []
        self.gen_delete = BlobGenerator('loadOne', 'loadOne-', self._value_size, start=0, end=int((self.num_items) * (float)(self._percent_delete) / 100))
        tasks.extend(self._async_load_all_buckets(self.src_master, self.gen_delete, "delete", 0))

        # Step-6 XDCR Remote -> Source
        self._replicate_clusters(self.dest_master, src_cluster_name)
        self.merge_buckets(self.dest_master, self.src_master, bidirection=False)

        # Wait for delete tasks to be finished
        for task in tasks:
            task.result()

        # Step-8 Compare the source and destination cluster items - item count, meta data, data content.
        self.verify_results(verify_src=True)

        # Verify if no deletion performed at source node:
        src_master_buckets = self._get_cluster_buckets(self.src_master)
        for bucket in src_master_buckets:
            src_stat_ep_num_ops_del_meta = int(StatsCommon.get_stats([self.src_master], bucket, '', 'ep_num_ops_del_meta')[self.src_master])
            src_stat_ep_num_ops_set_meta = int(StatsCommon.get_stats([self.src_master], bucket, '', 'ep_num_ops_set_meta')[self.src_master])
            self.assertEqual(src_stat_ep_num_ops_set_meta, 0, "Number of set [%s] operation occurs at bucket = %s, while expected to 0" % (src_stat_ep_num_ops_set_meta, bucket))
            self.assertEqual(src_stat_ep_num_ops_del_meta, 0, "Number of delete [%s] operation occurs at bucket = %s, while expected to 0" % (src_stat_ep_num_ops_del_meta, bucket))
            if self.rep_type == "xmem":
                src_stat_ep_num_ops_del_meta_res_fail = int(StatsCommon.get_stats([self.src_master], bucket, '', 'ep_num_ops_del_meta_res_fail')[self.src_master])
                src_stat_ep_num_ops_set_meta_res_fail = int(StatsCommon.get_stats([self.src_master], bucket, '', 'ep_num_ops_set_meta_res_fail')[self.src_master])
                dest_stat_ep_num_ops_del_meta = int(StatsCommon.get_stats([self.dest_master], bucket, '', 'ep_num_ops_del_meta')[self.dest_master])

                self.assertEqual(src_stat_ep_num_ops_del_meta_res_fail, dest_stat_ep_num_ops_del_meta, "Number of failed delete [%s] operation occurs at bucket = %s, while expected to %s" % (src_stat_ep_num_ops_del_meta_res_fail, bucket, dest_stat_ep_num_ops_del_meta))
                self.assertTrue(src_stat_ep_num_ops_set_meta_res_fail > 0, "Number of failed set [%s] operation occurs at bucket = %s, while expected greater than 0" % (src_stat_ep_num_ops_set_meta_res_fail, bucket))
            elif self.rep_type == "capi":
                src_stat_ep_num_ops_get_meta = int(StatsCommon.get_stats([self.src_master], bucket, '', 'ep_num_ops_get_meta')[self.src_master])
                self.assertTrue(src_stat_ep_num_ops_get_meta > 0, "Number of get [%s] operation occurs at bucket = %s, while expected greater than 0" % (src_stat_ep_num_ops_get_meta, bucket))

    def test_diff_version_xdcr(self):
        self.gen_create2 = BlobGenerator('loadTwo', 'loadTwo', self._value_size, end=self.num_items)
        self.gen_delete2 = BlobGenerator('loadTwo', 'loadTwo-', self._value_size,
            start=int((self.num_items) * (float)(100 - self._percent_delete) / 100), end=self.num_items)
        self.gen_update2 = BlobGenerator('loadTwo', 'loadTwo-', self._value_size, start=0,
            end=int(self.num_items * (float)(self._percent_update) / 100))

        # Step-2 Setting up replication clusters.
        src_cluster_name, dest_cluster_name = "remote-dest-src", "remote-src-dest"
        self.__setup_replication_clusters(self.src_master, self.dest_master, src_cluster_name, dest_cluster_name)

        self.rep_type = "capi"
        self._replicate_clusters(self.src_master, dest_cluster_name)

        self.rep_type = "xmem"
        self._replicate_clusters(self.dest_master, src_cluster_name)

        # Step-3 Load 10k items ( sets=80, deletes=20) on source cluster.
        self._load_all_buckets(self.src_master, self.gen_create, "create", 0)
        self._load_all_buckets(self.dest_master, self.gen_create2, "create", 0)
        self._async_update_delete_data()
        # Step-4 XDCR Source -> Remote
        self.merge_buckets(self.src_master, self.dest_master, bidirection=True)

        # Step-5 verify data
        self.sleep(120)
        self.verify_results(verify_src=True)